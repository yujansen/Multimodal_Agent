"""Pinocchio â€” Multimodal Self-Evolving Agent

Entry-point for interactive CLI usage.

Usage
-----
    python main.py

Optional env vars:
    PINOCCHIO_MODEL       â€” LLM model name (default: qwen2.5-omni)
    OPENAI_BASE_URL       â€” Custom API base URL (default: http://localhost:11434/v1)
    PINOCCHIO_DATA_DIR    â€” Directory for persistent memory (default: data)
"""

from __future__ import annotations

import sys

from config import PinocchioConfig
from pinocchio import Pinocchio


def main() -> None:
    cfg = PinocchioConfig()

    agent = Pinocchio(
        model=cfg.model,
        api_key=cfg.api_key,
        base_url=cfg.base_url,
        data_dir=cfg.data_dir,
        verbose=cfg.verbose,
    )

    print(agent.greet())
    print()
    print("è¾“å…¥æ¶ˆæ¯ä¸ Pinocchio å¯¹è¯ (è¾“å…¥ 'quit' é€€å‡º, 'status' æŸ¥çœ‹çŠ¶æ€)")
    print("â”€" * 60)

    while True:
        try:
            user_input = input("\nğŸ§‘ You: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nå†è§ï¼ğŸ‘‹")
            break

        if not user_input:
            continue

        if user_input.lower() in ("quit", "exit", "q"):
            print("å†è§ï¼Pinocchio ä¼šè®°ä½ä»Šå¤©å­¦åˆ°çš„ä¸€åˆ‡ã€‚ğŸ‘‹")
            break

        if user_input.lower() == "status":
            import json
            status = agent.status()
            print(json.dumps(status, ensure_ascii=False, indent=2))
            continue

        if user_input.lower() == "reset":
            agent.reset()
            print("ä¼šè¯å·²é‡ç½®ï¼ˆæŒä¹…åŒ–è®°å¿†ä¿ç•™ï¼‰ã€‚")
            continue

        # â”€â”€ Run the cognitive loop â”€â”€
        response = agent.chat(user_input)
        print(f"\nğŸ¤– Pinocchio: {response}")


if __name__ == "__main__":
    main()
